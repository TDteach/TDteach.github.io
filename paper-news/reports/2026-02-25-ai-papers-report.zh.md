# AI 与 AI 安全每日论文报告
## 2026-02-25

**生成时间**：2026-02-25 23:23:52  
**论文数量**：22

---

## 1. 研究问题

### 幻觉/事实性
- 基于 LLM 的学术问答工具正被越来越多地用于帮助研究者在大量科学文献基础上进行综合与编辑，但它们可能产生细微且高风险的错误，例如缺乏依据的断言与关键信息遗漏。论文指出，常见的溯源机制——尤其是粗粒度的来源引用——对于严格的学术核查而言粒度不足，甚至可能不准确或出现幻觉，使领域专家无法以可操作的方式验证具体断言（p. 2，Section 1）。这带来信任与依赖校准问题：研究者不仅需要知道使用了哪些文档，还需要知道 LLM 答案中的哪些具体主张由哪些证据支持，以及遗漏了哪些相关信息。作者进一步指出，学术工作时间紧迫且认知负荷高，因此即便用户产生怀疑，如果核查成本过高，也可能不会改变行为（p. 2，Section 1）。核心问题因此包含两方面：（1）设计与学术论证结构对齐的细粒度溯源（由证据支持的主张）；（2）理解这种溯源在真实学术编辑工作流中是否确实改变用户的信任感知与依赖行为。解决该问题很重要，因为缺乏依据或细微错误的学术输出可能在学术传播中扩散；同时，仅改变态度（信任）的界面干预在真实约束下可能无法改变行为（依赖）（p. 2，Section 1；p. 16–17，Section 7.1）。
- 大型视觉-语言模型（LVLMs）可能生成流畅但错误、且不受输入图像支持的回答（幻觉），在真实部署中带来安全与可靠性风险（p. 1，Abstract；p. 1，Introduction）。提升可靠性的常见方式是自我评估：模型利用内部信号估计自身输出是否正确，从而避免昂贵的外部评审器（外部评审器本身也可能幻觉）（p. 1，Introduction）。然而，现有自评方法多源自纯语言场景，往往依赖语言先验（如常见文本联想），而非验证答案是否扎根于视觉证据（p. 2，Introduction；p. 3，Section 4.1）。论文强调一种失效模式：当图像与常见预期相矛盾时，标准的不确定性评分仍可能对幻觉答案给出低不确定性，因为模型受语言规律影响而保持自信（p. 2，Introduction；p. 1，Fig. 1 caption；p. 3，Section 4.1）。这在反事实或对抗构造场景中尤为严重，因为视觉扎根至关重要。核心问题因此是：设计一种无需训练的 LVLM 自评分数，显式衡量模型预测对视觉证据的依赖程度，使置信度反映“扎根”而非“流畅”（p. 2，Introduction；p. 3，Section 4.1）。

### 其他
- 信息不足。
- 基于 LLM 的智能体越来越被期望通过命令行界面（CLI）解决真实世界任务，其中成功需要与实时环境进行多步交互（如安装依赖、编辑文件、运行测试、调试）。尽管 Terminal-Bench 等基准在容器化环境中以可编程方式验证这些能力，但能训练出强终端智能体的数据策略往往未公开，使实践者缺乏如何构建有效监督微调（SFT）终端交互数据集的明确指导（p. 2，Introduction；p. 1，Abstract）。论文提出扩展智能体终端数据的两个实际瓶颈：（1）多样化提示、依赖文件、预配置环境等基础资源稀缺；（2）收集轨迹的物流与计算复杂度高，因为真实人类终端轨迹难以捕获，而合成 rollout 由于每任务环境实例化与多轮交互而成本高（p. 2，Introduction）。现有方法要么侧重智能体脚手架，要么通过适配器将现有数据集包装成终端接口，但适配器可能继承非交互数据集的结构假设，多智能体生成流水线也可能难以规模化（p. 2，Introduction；p. 3，Related Work）。核心问题因此是：如何工程化可扩展、多样且高质量的训练数据——同时覆盖广泛基础技能与终端特定操作技能——使相对中等规模的开源模型在真实基准上显著提升终端表现（p. 4，Section 4；p. 8，Section 5.2）。
- 测试时训练（TTT）已从分布偏移下的适配技术演化为一种序列建模的架构原语，可作为 softmax 注意力的替代方案，并在自回归推理中具备线性时间计算与常数内存等效率优势（p. 1，Section 1）。其中一个重要变体 TTT with key–value binding（TTT-KVB）通常被解释为在线元学习/快速权重机制：在内循环中“记忆”键值映射，再通过将更新后的快速权重函数作用于查询来“检索”信息（p. 1，Section 1；p. 3，Section 3）。这种存储-检索解释推动了越来越复杂的架构选择（如更复杂的优化器、归一化、更深的内循环网络）以提升记忆保真度（p. 1，Section 1）。论文认为该主流解释与训练后 TTT 模型的观测行为不一致。作者识别出若干经验“悖论”，与“内循环确实在做有用记忆与基于查询检索”的预期相矛盾：内循环拟合更好时下游性能反而变差；用梯度上升替代梯度下降不损害性能；查询与键的分布可不匹配；用键替换查询影响甚微（p. 1，Section 1；p. 3–4，Section 4）。这些异常重要，因为它们暗示当前对 TTT 的设计直觉可能误导，导致不必要的复杂性并错失简化与加速机会。核心问题因此是：正确刻画 TTT-KVB 层实现的计算，并用该刻画解释这些悖论，从而实现更有原则、更高效的设计（p. 2，Section 1；p. 4–6，Section 5；p. 7–8，Section 6）。
- 大多数针对大语言模型（LLM）的逻辑推理评测聚焦于收敛式推理：对给定前提产出一个正确证明或最终标签。论文认为这忽略了推理问题的一个重要现实属性：许多结论可由多条不同且有效的推导支持，优秀推理器应能探索并枚举替代证明路径，而非过早锁定单一路径。作者将其形式化为多路径逻辑推理任务：给定前提 P 与目标假设 G，模型应枚举所有能蕴含 G 的、彼此不同的逻辑有效推导路径，而不仅是判断是否蕴含。作者将每条推导路径定义为一个最小支持集 S：S 蕴含 G，且 S 的任何真子集都不蕴含 G。构建该任务基准具有挑战，因为需要（i）可扩展构造并对所有最小证明给出穷尽真值，（ii）可靠评估开放式、多解的自然语言证明生成，（iii）能区分“仅正确”与“真正探索/覆盖证明空间”的指标。缺乏这样的基准与评估时，即便模型在标准准确率下表现强，也可能系统性遗漏其他有效证明路径，从而掩盖其在灵活推理与搜索行为方面的关键局限，尤其当推理深度与分支度增加时更为明显。
- 信息不足。
- 思维链（CoT）提示广泛用于诱导大语言模型进行多步推理，从而提升推理密集任务的准确率，但它常产生很长的推理文本，增加生产环境中的推理延迟与成本（p. 1，Section 1）。这带来高准确率/高计算推理与更快的零样本推理（但可能缺乏推理深度）之间的实际权衡（p. 1，Section 1）。业界常见应对是通过微调进行知识蒸馏，让较小“学生”模型模仿较大“教师”，包括蒸馏逐步推理轨迹的方法（p. 1，Section 1；p. 2，Section 2.2）。但论文认为参数化蒸馏/微调带来运维负担：当仅有教师文本输出时可能无法迁移真实推理；教师或领域逻辑变化时需要再训练；难以扩展到多用例；且常需大量精心整理的数据以避免灾难性遗忘等问题（p. 1–2，Section 1）。核心问题因此是：如何在保留可解释性的同时，将推理能力迁移到更小或更便宜的模型，并避免 CoT 的延迟开销与微调的维护开销。论文聚焦于推理密集的分类场景（如法律 NLI、类似合规的决策边界），这些场景要求决策可核查且不希望运行时生成长推理文本（p. 2，Section 1；p. 3，Section 3）。
- 论文报告并记录了由 Gemini 3 Deep Think 驱动的数学研究智能体 Aletheia 在首届 FirstProof 挑战中的表现。该挑战包含十道研究级数学问题，旨在评估 AI 在职业数学家工作中出现的问题上的能力。论文要解决的核心议题是：在挑战规则未完全形式化的情况下，如何解释并操作化“自主”研究级解题。FirstProof FAQ 强调：若 AI 能在无需人类提供数学思路、并带有适当引用的前提下，自主产出符合数学文献严谨性与学术标准的证明，则可视为“已回答”。作者认为“自主性”的界定仍存在歧义（例如是否允许事后澄清请求、是否允许人类在多次运行中挑选最佳尝试），而这些选择会实质影响报告的性能。在此背景下，论文目标是透明呈现一个评估流水线：（i）确保解答生成过程中无人类干预；（ii）使用固定的验证/抽取提示词将输出标准化为可发表证明；（iii）由数学专家在明确阐释的标准下评判正确性（“小修后可发表”）。更广泛的动机是理解当前 AI 在研究数学上的可靠性与能力，包括智能体在无法在约束内产出解答时倾向于自我筛选并返回“无解”。
- 信息不足。
- 论文研究“Diligent Learner”框架中的一个关键经验瓶颈：随着多步推理深度增加，大语言模型（LLM）能否维持非消失的逐步成功概率（记为 γ）。在 Diligent Learner 视角下，推理被建模为在验证器引导下对语义步骤进行搜索；只有当模型的提议分布在每个深度都对“好的”下一步保留足够概率质量时，测试时搜索才能扩展以解决有界深度问题（p. 5，Section 3.1）。尽管理论在 γ 保持远离 0 时给出保证，但在需要每步将累积状态与新证据整合的分布外（OOD）逻辑推断任务上，γ 是否会崩塌仍不清楚（p. 1–2，Introduction）。作者认为现有推理基准不足以测量 γ，因为它们常只评分最终答案、允许多种有效中间轨迹，或允许模式匹配/记忆基准规律等捷径（p. 2，Introduction；p. 4–5）。为此，他们设计了一个基准：每一步都有唯一正确延续，且忽略已揭示历史（前缀）或忽略每步新证据在信息论意义上都应无效（p. 2；p. 4–6）。该问题重要在于：若 γ 在此类 OOD 任务上随深度急剧下降，则仅增加测试时计算/搜索无法带来稳健的长时程推理；反之，若 γ 可被稳定（如借助工具），则支持 Diligent Learner 路径通向高能力智能体的可行性（p. 5；p. 14–16）。
- 在超长序列上训练 Transformer 受 GPU 内存限制，尤其是训练时所需的激活内存。上下文并行（也称序列并行）通过在多设备间切分序列来支持比单加速器更长的上下文。然而，主流上下文并行方法（如 Ring Attention、DeepSpeed-Ulysses）主要关注在上下文维度扩展计算/通信，而每设备激活内存仍随序列长度线性增长，在多百万 token 上下文时可能成为瓶颈（p. 1，Section 1）。论文认为，在约多百万 token 以上，即便进行分布式切分，自注意力中的中间张量——尤其是全头 QKV 张量与 all-to-all 通信缓冲区——会形成“激活内存屏障”，阻止进一步扩展（p. 1，Section 1；p. 5，Section 3.2）。现有进一步扩展上下文的方法（如 FPDT 或激活卸载）可缓解 GPU 内存压力，但常因 CPU 参与与数据传输而牺牲吞吐（p. 1，Abstract；p. 3，Section 2.1；p. 7，Section 5.2）。核心问题因此是：在上下文并行下，通过减少注意力激活内存（尤其是中间张量与通信缓冲区）来提升可训练最大上下文长度，同时保持与 Ulysses 等高性能基线相当的训练吞吐（p. 1，Abstract；p. 2，Section 1）。
- 选择性状态空间模型（SSM）（如 Mamba）因其流式线性时间处理与紧凑循环状态而越来越多地作为大语言模型骨干，尤其适用于长上下文工作负载。但在推理部署时，SSM 服务性能常受单 GPU 限制：显存容量（权重与运行时缓冲）、带宽与延迟。随着模型规模与支持上下文长度增长，单 GPU 执行不足，多 GPU 推理变得必要。尽管张量并行（TP）是扩展 Transformer 推理的标准方法，将其应用到选择性 SSM 模块并不直接。SSM mixer 将大投影与对局部布局敏感的操作（深度可分离卷积与序列级循环状态更新/scan）结合，这些操作依赖连续的按通道布局与最小同步。若直接复用 Transformer 的 TP 切分模式，可能打散打包的中间张量，并在 mixer 多处引入额外 AllGather/AllReduce，使同步进入关键路径并损害吞吐。此外，自回归服务包含 prefill 与 decode 阶段；若无精心缓存，SSM 可能为每个生成 token 冗余重处理提示上下文，增加延迟。论文针对这些系统挑战，设计了面向选择性 SSM 推理的通信高效 TP 方法，目标是提升吞吐、降低延迟（含首 token 时间），并通过跨多 GPU 分摊内存占用来支持更长提示。
- 晚交互多向量检索（如 ColBERT 风格 MaxSim）已成为跨模态（文本、视觉文档、视频）检索的强范式。但其存储与查询时计算随文档长度线性扩展，因为每个文档 token（或帧/音频 token）都会贡献一个向量进入索引。对于单条内容可能包含数千 token 的多模态语料，这种线性依赖会变得不可承受，导致索引极大且打分成本高（论文给出视频索引规模的粗略估算）（p. 1，Introduction；p. 2，Introduction）。论文还认为这种成本常是浪费：在多模态晚交互中，许多被索引的向量在检索时利用率很低，因此全长度索引相对其代价呈现收益递减（p. 2，Introduction；p. 8–9，Section 6.5）。核心问题因此是：如何在与查询无关的前提下压缩多向量文档表示（因为索引建立发生在查询未知之前），同时保留晚交互区分相关文档与困难负例所需的细粒度判别信息（p. 3，Section 3.1；p. 2，“Attention-based Compression”）。论文将其表述为学习或构造从任意长度文档到固定大小 m 个向量（常数向量预算）的映射，使索引大小与查询时打分成本有界且可按计算/存储约束调节，同时不放弃多向量匹配的优势（p. 3，Section 3.1）。
- 信息不足。
- 论文讨论普通用户首次接触陌生且复杂的知识图谱（KG）时面临的特定障碍：他们往往甚至无法开始探索，因为缺乏形成起点所需的方向感。作者认为，现有 KG 可用性与探索式搜索讨论对早期困难的处理较为碎片化，并通常假设用户能从“某处”开始（如发起查询、选择分面、从初始实体导航）。相反，在首次接触时，普通用户可能不知道 KG 包含什么、知识如何组织、或如何用形式化查询语言表达问题，从而阻止任何有意义的初始交互。作者将其理论化为初始探索问题（Initial Exploration Problem, IEP）：一种在首次接触陌生 KG 时出现的、时间上有界的“前目标（pre-goal）”状态。IEP 之所以重要，是因为 KG 在多个领域（如医学、百科知识库、数字人文）日益普及，但若非专家用户无法进入与使用，KG 的收益就难以触达目标群体。论文声称许多界面内嵌了认识论假设（如用户能表述查询或理解模式元素），而这些假设在首次接触时并不成立，从而在设计空间中形成结构性缺口：缺乏在不要求用户事先知道该问什么或本体如何组织的情况下揭示 KG 范围的机制。作者提出 IEP 作为评估 KG 界面的理论视角，并推动为初始探索提供入口脚手架（p. 2，Introduction；p. 6–8，Section 4）。

### 隐私/安全
- 由 LLM 驱动的智能体系统越来越多地作为可信副驾驶用于高后果任务（如邮件处理、招聘、医疗文档）。这种信任带来一种独特安全风险，论文称之为智能体中介欺骗（Agent-Mediated Deception, AMD）：攻击者并非仅攻击模型本身，而是破坏智能体工作流的部分环节（如感知输入、记忆或工具），使智能体忠实执行被篡改的任务，并说服人类用户接受被操纵的结果。核心问题不仅是智能体是否会被攻破（以智能体为中心的安全），还包括当被委托的智能体变成具有欺骗性的“内部威胁”时，人类能否检测并做出恰当响应。论文认为 AMD 不同于传统在线欺骗（如钓鱼/错误信息），因为用户处于“主动委托”心态，欺骗通过可信助手中介，可能绕过对外部信息的常规怀疑（p. 1–3，Sections I–II.D）。工作聚焦三个研究问题：（RQ1）用户对 AMD 的易感性如何，（RQ2）哪些认知因素预测易感性，（RQ3）如何设计以人为中心的防御（p. 1，Section I）。动机在于该场景的人因研究不足，仅依赖技术防御风险很高，因为智能体在开放、不可信环境中运行，完美技术保障不太可能实现（p. 12，Section VI）。因此，需要在真实智能体工作流下测量真实用户行为，以理解智能体系统的真实安全态势并指导能有效支持人类监督的防御设计。

### 鲁棒性
- 基于 LLM 的智能体越来越多地用于复杂的工具使用任务（如网页浏览、代码执行、数据分析），但现有基准大多无法衡量这些系统是否能进行真实的信息综合：从多来源收集证据并整合以推断超越简单事实检索的洞见。论文认为许多基准过度强调浅层检索、依赖单一知名来源（如 Wikipedia），且常以英语为中心，限制了其在全球分布、异质信息生态中评估智能体的能力。在真实决策场景（如政策、旅行、社会经济分析）中，回答问题往往需要导航多个网站、抽取结构化与非结构化数据、进行计算，并产出可验证的结构化输出。作者因此瞄准“深度”综合任务的评估缺口：这些任务耗时且多步，答案无法逐字检索，需要分析（如趋势检测、排序、相关性）。他们还强调需要可验证、随时间稳定的答案以支持可复现评估，同时仍要对记忆与污染保持鲁棒。核心问题因此是创建一个评估基准，使其（1）反映真实世界多来源综合，（2）可验证且随时间稳定，（3）跨地区与领域多样，（4）足够困难以暴露当前智能体的局限，如幻觉、导航失败、在大信息空间中的脆弱推理。
- Pass@k 是可验证 LLM 任务（如数学/代码）的标准指标：模型可独立采样 k 个解，由验证器检查正确性；若任一通过则成功（p. 3，Section 2）。该指标推动了通过策略梯度直接优化 pass@k 的后训练方法，以匹配推理时的多采样流程（p. 1，Section 1；p. 4，Section 2）。然而，多项先前工作报告一个反复出现且在实践中成问题的权衡：优化 pass@k 可能提升 pass@k，却降低 pass@1（单次成功率）（p. 1，Section 1）。论文认为这很重要，因为 pass@1 常仍是运维约束：受延迟/成本预算限制、验证器覆盖不完美、以及需要可靠的单次回退方案（p. 2，“Why this degradation matters.”）。核心问题因此是解释：为何以及在何种情况下，面向多样本成功（pass@k）的推理感知优化会损害单样本性能（pass@1），尽管对每个提示而言 pass@k 梯度只是 pass@1 梯度的正比例缩放（p. 7，Section 4.1；p. 4，Section 2）。作者将开放问题表述为理解这种退化背后的机制，并给出其发生条件，从而使未来推理感知微调能在提升多次尝试性能的同时避免牺牲 pass@1（p. 2，“Open question.”；p. 15，Section 7）。
- 基于 LLM 的智能体在交互式环境中通过生成多步动作轨迹而非单次响应来工作。用强化学习训练此类智能体常依赖稀疏结果奖励（如成功/失败），对哪些中间决策有益或有害提供的指导有限。先前工作引入了逐步信用分配以在步骤间分配奖励，但论文认为仍有一个关键学习信号未被充分利用：LLM 的内在不确定性。作者指出不确定性重要，因为它反映每个决策点的置信度，可指示何时需要探索（高不确定性）与何时应强化行为以收敛（低不确定性）。此外，即便轨迹失败，不确定性也可能提供信息反馈，使得能从原本“无信息”的失败中学习。核心问题因此是：如何为 RL 训练的 LLM 智能体设计奖励，使其（i）将不确定性作为与置信度对齐的稠密内部信号纳入；（ii）重塑奖励，使失败轨迹也能贡献有用学习信号，从而提升在 ALFWorld、WebShop 等交互基准上的探索效率与训练稳定性。（p. 1 Abstract；p. 2 Introduction；p. 5–6 Section 3.3）
- 多智能体模仿学习（MA-IL）旨在从马尔可夫博弈中的专家交互示范中学习策略。以往离线 IL 理论常以性能/次优性（学习到的联合策略与专家价值的接近程度）给出保证，但这并未覆盖战略鲁棒性：学习到的联合策略可能高度可被利用，因为某个智能体可通过单边偏离获益。论文研究这一缺口，考察离线模仿学习得到的乘积策略距离纳什均衡可能有多远，以纳什间隙（Nash gap：玩家单边最优改进的最大值）衡量。核心问题在于：常见离线 MA-IL 目标/诊断——行为克隆（BC）误差与占用度量匹配误差——在一般马尔可夫博弈中并不能可靠预测可被利用性。作者询问何时能得到（i）一致界（模仿误差趋零时纳什间隙趋零）与（ii）可处理界（可高效计算，从而训练中可监控）。他们表明即便在理想化情形（精确度量匹配）且即便博弈已知，也存在根本障碍：精确匹配仍可能产生高度可被利用的策略；并且在给定近似误差下计算可达可被利用性的紧下界在计算上可能不可处理。随后他们识别出结构性假设——战略支配与最佳响应的连续性性质——可使 BC 误差与纳什间隙之间建立一致、可处理的上界。（纳什间隙与 BC/度量匹配误差定义：p. 4，Section 3.3；动机与贡献：p. 1–2，Introduction。）
- 论文讨论工业推荐系统预排序中的样本选择偏差与训练-服务不一致。在级联推荐中，预排序需高效为数千召回物品打分，并仅将少量子集传递给下游排序。然而，预排序模型通常只在已曝光交互（实际展示给用户且有点击/购买反馈的物品）上训练，而在线服务时必须为整个召回集合打分，其中包含大量未曝光候选（被上游召回但从未展示，因此无反馈）（p. 1，Introduction；p. 3，Section 3.1）。这种不匹配导致分布偏移与严重样本选择偏差，因为曝光本身是有偏的（如偏向热门物品），从而损害泛化并抑制长尾或新内容发现（p. 1，Introduction；p. 3，Section 3.1）。现有缓解策略——将未曝光物品当作负例进行负采样、收集随机探索流量、从下游排序器蒸馏伪标签、或对抗式域适配——要么制造假负例、要么成本高/风险大、要么传播由曝光日志训练的教师模型的曝光偏差（p. 1–2，Introduction；p. 2，Section 2.1）。核心问题因此是：如何为未曝光候选获得可靠监督，使预排序训练分布更匹配在线服务空间，在不增加在线延迟的情况下提升鲁棒性与多样性（p. 2，Introduction；p. 5，Section 3.5）。

---

## 2. 方法与途径

### 幻觉/事实性
- PaperTrail 是一个系统与界面，用“以论证为基础的溯源”来操作化：将源论文与 LLM 答案都分解为离散的主张与证据，并进行匹配以暴露被支持的主张、不被支持的主张以及遗漏（p. 2，Section 1；p. 4–8，Section 3）。后端采用三阶段流水线（Fig. 2）：（阶段 1）离线的论文级主张抽取：使用 LLM（Gemini 2.5 Pro）提示其从每段抽取原子化、可验证、忠实、去语境、陈述式主张；证据候选通过 sentence-transformer 相似度检索（余弦阈值 0.75）并扩展上下文句子以提升可读性（p. 4–5，Section 3.1.1）。（阶段 2）实时答案生成（研究设置中为文档扎根 QA），随后用 LLM 将答案主张与支持证据抽取为结构化 JSON；通过句子分词与字符位置匹配将跨度映射回文本以高亮（p. 5，Section 3.1.2）。（阶段 3）实时匹配：通过结合 SPECTER 嵌入相似度检索与 LLM 选择的 RAG 风格流程选取相关论文主张/证据；再由 LLM 执行主张-主张语义等价匹配；答案证据用余弦相似度“验证”，并用较宽松阈值（<0.55）标记潜在不被支持的证据（p. 7，Section 3.1.3）。前端为三联动面板：任务编辑器、聊天与溯源面板，展示主张覆盖与包含/遗漏主张卡片（p. 7–8，Section 3.2；Fig. 3）。作者评估（a）在 SciClaimHunt 与 BioClaimDetect 上的离线主张抽取质量，使用 SPECTER 相似度匹配（τ=0.9）计算 precision/recall/F1（p. 8–10，Section 4）；以及（b）一项被试内用户研究（N=26），比较 PaperTrail 与引用式基线在两项学术编辑任务中的表现，测量信任（TXAI）、依赖（归一化 token 级 Levenshtein 相似度）、信心，以及次要工作负载/可用性指标（p. 10–13，Sections 5–6；Table 1）。
- VAUQ 是一个无需训练的自我评估框架，将预测不确定性与对视觉信息利用的显式度量结合（p. 2，Introduction；p. 4，Section 4.2；Fig. 2）。首先，它计算在给定图像 token v 与文本提示 t 时生成序列的长度归一化预测熵 H(y|v,t)（p. 4，Definition 4.1 footnote）。其次，引入图像信息分数（IS），通过比较有无视觉 token 的熵来衡量图像降低不确定性的程度：IS_blank = H(y|∅,t) − H(y|v,t)（p. 4，Eq. 2）。为降低对虚假背景相关性的敏感性，VAUQ 使用基于模型视觉注意力的无监督核心区域遮罩策略（p. 4，Section 4.2）。它在生成 token 到图像 token 的注意力上跨头与连续层范围（ls 到 le）聚合：Attn(vi) = Σ_{l=ls..le} Σ_h Σ_j A^{(l,h)}(y_j, v_i)（p. 5，Eq. 3）。随后选择注意力最高的前 K% 图像 patch v_top（p. 5，Eq. 4），将其遮罩得到 v_masked，并计算核心遮罩信息分数 IScore = H(y|v_masked,t) − H(y|v,t)（p. 5，Eq. 5）。最后，VAUQ 定义评分函数 s_VAUQ(x,y) = H(y|v,t) − α·IScore，其中 α 用于加权对核心视觉证据依赖弱的惩罚（p. 5，Eq. 6）。实现采用贪心解码（最大长度 128），并为效率在计算 IScore 时遮罩注意力权重（attention knockout）而非原始像素（p. 12，Appendix A）。

### 其他
- 信息不足。
- 论文提出一个由粗到细的数据工程框架 Terminal-Task-Gen，结合（i）数据集适配与（ii）合成任务生成，随后进行轨迹生成与后处理，产出 SFT 语料（Terminal-Corpus）（p. 1，Fig. 1 caption；p. 4，Section 4）。在数据集适配方面，作者选择覆盖数学、代码与软件工程（SWE）的提示数据集，并将每个提示映射为 Terminal-Bench 风格指令：使用 Terminus 2 系统提示模板与数据集特定指令后缀；SWE 提示还会将引用的代码文件实例化到环境中，但这些适配任务不包含测试用例（p. 5，Section 4.1.2；p. 18，Figs. 8–10）。在合成任务生成方面，使用两种方法：基于种子的生成（LLM 将结构化种子问题转为自包含终端任务，生成输入文件与 pytest 测试；若存在参考解，仅用于推导测试期望且不暴露给智能体）与基于技能的生成（LLM 从覆盖 9 个领域的原子技能分类体系中组合任务，通常每任务组合 3–5 个技能）（p. 5–7，Sections 4.2.1–4.2.2）。两种方法都输出包含提示、pytest 测试（带权重）、文件与领域特定 Docker 环境的任务；它们避免生成 oracle 解并强调解答隔离以防泄漏（p. 7，Section 4.2.3）。为规模化生成，使用 9 个预构建领域 Docker 镜像而非每任务 Dockerfile（p. 7，Section 4.2.3）。DeepSeek-V3.2 作为教师模型，通过 Terminus 2 智能体脚手架生成合成任务与轨迹（p. 7，Section 4.3；p. 4，Section 3.2）。后处理包括：对 Terminal-Bench 2.0 测试样本进行 14-gram 重叠去污染、质量过滤（身份泄漏、中文字符），并消融额外轨迹过滤选择（p. 8，Section 4.4；p. 9–10，Sections 5.4–5.5）。模型（Nemotron-Terminal）从 Qwen3 8B/14B/32B 进行 SFT 训练，使用指定超参（如最大序列长度 32,768），并在 Terminal-Bench 2.0 上用 Terminus 2 参考智能体评测（p. 8，Section 5.1；p. 4，Section 3.1）。
- 论文结合经验探针与解析重写。经验上，通过在推理时操控内循环行为并测量下游任务指标来检验“记忆”观点的预测。例如：改变内循环梯度步数（显示内循环损失改善但任务性能下降；Fig. 1，p. 3–4，Section 4.1）、用梯度上升替代梯度下降（Table 1，p. 4，Section 4.2）、用 t-SNE 可视化查询/键分布以评估分布重叠（Fig. 2，p. 4，Section 4.3）、以及在计算输出时用键替换查询（Table 1，p. 4，Section 4.4）。解析上，作者将内循环更新“展开（unroll）”，并证明一大类 TTT-KVB 架构可重写为一种学习到的类线性注意力算子。关键技术条件是内循环函数具有线性、无偏置的最后一层 f(x)=ϕ(x;Θ)W（p. 5，Theorem 5.1）。在对键输入进行一次梯度步后，更新后的输出在查询上可写成线性注意力形式 o = q̂ (S0 + k̂^T v̂)，其中 q̂、k̂、v̂ 由网络特征与损失梯度诱导（p. 5，Theorem 5.1）。在序列上重复可得到对历史的“扩展”线性注意力累积（p. 5，Theorem 5.2）。框架扩展到带动量的梯度下降，得到动量加权的有效 value（p. 5，Theorem 5.3）。随后将该化简实例化到具体 TTT 变体：LaCT（含 SwiGLU 内循环 MLP、Frobenius 内积损失、逐 token 学习率、动量、梯度正交化）被重写为类线性注意力形式（p. 6，Section 5.3；Appendix E）；ViTTT 的 GLU 与深度卷积快速权重组件也被表达为类线性注意力机制（p. 6–7，Section 5.4；Appendix F–G）。最后，作者据此定义一条消融轨迹，逐步移除或简化内循环组件（如仅更新最后一层、移除权重归一化、降低 MLP 深度、移除逐 token 学习率、移除动量、移除梯度正交化），并评估性能/吞吐，包括在满足结合律时可启用的并行形式（p. 7–8，Section 6；Table 2；Appendix H–I）。
- LogicGraph 通过自动化的神经-符号流水线构建，保证穷尽的多路径真值。首先，作者通过从采样结论出发的反向（自底向上）构造生成符号化“Logic DAG”：对每个节点从七种基本论证形式中采样一种（如 Modus Ponens、Modus Tollens、Hypothetical Syllogism、Disjunctive Syllogism、Constructive Dilemma、Reductio ad Absurdum、Disjunction Elimination），并生成父前提，递归扩展到目标深度。为产生多路径，他们先构建初始链，再选择中间结论向上再次扩展，生成共享推理节点的 DAG；为避免意外额外路径，除非显式共享节点，否则分配新的原子标识符。第二，将符号 DAG 语义实例化为 Prover9 表达式，再转为自然语言叙事：从 32 种抽象实体类型采样，并用 LLM（Deepseek-V3.2-Exp）将抽象符号映射为领域谓词并口语化，同时保持逻辑关系。第三，用 Prover9 过滤/验证每个实例：对每条推理边做逐步蕴含检查、对从前提到目标的连通性做全局可导性检查、并做上下文可满足性检查以避免矛盾。对模型生成的多路径证明评估方面，作者提出无参考的神经-符号评估器：LLM 抽取并形式化每个自然语言步骤为 Prover9 风格逻辑，再由 Prover9 验证（i）每步从所引前提的局部有效性与（ii）最终目标从所用前提子集推出的全局有效性。他们还提供二维错误分类（语义理解 vs 逻辑执行），并定义收敛指标（成功率、精确率、最短路径发现率）与发散指标（解召回/多样性、家族召回/通用性、以及基于跨模型逆频率的原创性）。
- 信息不足。
- 论文提出 Prompt-Level Distillation（PLD，提示级蒸馏），一种监督式、非参数化框架：将教师模型的推理“编译”进学生模型的系统提示词，而非更新模型权重（p. 2，Section 1；p. 3，Section 3）。PLD 有四个阶段（Fig. 1；p. 3，Section 3）。阶段 1（监督式指令抽取）使用带标注训练集 T={(xi, yi)}，提示一个推理优化的教师模型（i）生成支持金标签的 CoT 推理，（ii）立即将该推理抽象为通用的“可执行”自然语言规则，得到增强数据集 D={(xi, yi, Ii)}（p. 3，Section 3.1；Appendix A.1）。阶段 2（聚类逻辑综合）用嵌入模型对微指令编码，并用 DBSCAN（余弦距离）聚类；丢弃离群/噪声点，再由教师（或同一模型）将每个簇综合为统一指令（p. 4，Section 3.2；Appendix C.1–C.2）。阶段 3（闭环冲突消解）迭代评估学生模型在训练/验证数据上的表现，隔离失败样例，并用冲突消解模型（同教师）结合失败与成功样例来改写指令；循环直至验证误差收敛（p. 4–5，Section 3.3）。阶段 4 将精炼后的统一指令集作为学生系统提示词用于零样本推理，目标是在运行时避免生成中间推理 token（p. 5，Section 3.4）。实验使用 Gemini 3 Flash/Pro 作为教师/冲突消解模型，并评估包括 Gemma-3 4B 与 Gemini 2 Flash 在 Contract-NLI 与 StereoSet 上的表现（p. 5，Section 4；p. 5，Section 4.3）。
- 作者通过将 FirstProof 题目陈述从官方 LaTeX 源逐字复制（不做修改）来提示 Aletheia。生成输出随后通过一个预先确定的“验证与抽取提示词”（Appendix A）并由 Gemini 3 Deep Think 执行，该提示词要求模型独立验证候选解、给出裁决（[CORRECT]/[WRONG]/[FIXABLE]），并在可修复时产出完整修正后的 LaTeX 证明。该提示词也用于直接诱导 LaTeX，避免人工重排格式。研究使用两种智能体变体，区别在于基座模型：Aletheia A（截至 2026 年 2 月与 Gemini 3 Deep Think 相同的基座模型）与 Aletheia B（先前工作引用的 2026 年 1 月 Gemini 基座模型）。他们在这两个智能体之间进行“best-of-2”选择，为每题指定一个优选解（由人类选择）用于报告。评估方面，他们为每题征求至少两位学术数学家的独立反馈，在信心较低时增加专家数量；结果以“认为解正确的专家人数”汇总。他们还报告特定题目的定性评注（如误解、关键缺陷或不完整），并讨论“推理成本”分析：绘制每题推理成本相对先前基线（Erdős-1051）的对比，特别指出第 7 题成本很高。论文还在 Appendix C 提供已解题目的原始提示/输出，并在 Appendix B 记录截止日前的内部评估。
- 信息不足。
- 论文引入一个 GF(2) 上的逐步布尔函数重建任务，目标函数以代数正规形（ANF）表示为若干单项式的 XOR。输入分为地址位 a 与载荷位 v，每个 ANF 项形如 tj(a,v)=aj·Mj(v)，其中 Mj(v) 是载荷变量子集 Sj 上的 (d−1) 次单项式（p. 6，Section 4.1，Eq. 3）。一个实例是支持集序列 (S1,…,Sn)，使得每一步的下一项唯一（p. 6，Section 4.1）。在第 g 步，模型接收（i）前缀 Pg=(t1,…,tg) 与（ii）从 step-g oracle 采样的新标注数据集 Sg，并需输出下一单项式 tg+1。逐步成功率定义为 γg = Pr[ t̂ = tg+1 ]，在模型以 (Pg,Sg) 为条件的随机策略下计算（p. 6，Section 4.1，Eq. 4）。为防止捷径，作者设计“统计混淆”采样 oracle：标签分解为依赖前缀的 mask XOR 下一项信号，因此仅用数据的求解器若不条件化前缀将看到近似随机标签（p. 8，Section 4.2，Eq. 6；Lemma 4.3）。他们还对支持集独立同分布采样，使前缀对下一支持集不提供信息，从而击败仅用历史的预测（p. 7，Section 4.2，Lemma 4.1）。载荷从固定汉明重量球面采样，并选择 w* 使单项式触发概率接近 1/2 以降低标签偏置（p. 7–8，Section 4.2，Lemma 4.2）。评估时将任务转为单轮提示，包含元数据、前缀项与 32 条带标签观测表；提示指定活跃地址变量并将搜索限制在载荷索引（p. 9，Section 5.1）。验证高效，因为只有一个有效延续；通过解析预测索引并比较集合来检查正确性（p. 10，Section 5.2）。他们还提供一个对勤勉求解器的多项式时间解码器，通过残差化与对正例求交实现（Appendix B，Eq. 7–8；Theorem B.1）。
- UPipe 被提出为 DeepSpeed-Ulysses 的一种“解绑定（untied）”变体，通过沿注意力头维度对注意力执行进行分块来降低注意力激活内存（p. 1，Abstract；p. 5，Section 3.3）。该方法建立在 DS-Ulysses 的做法之上：将序列在 C 个设备间切分，并用 all-to-all 将 QKV 从序列切分布局重分片为按头切分布局，使每个设备能对一部分头在全序列上做注意力（p. 4，Section 3.1）。UPipe 的关键变化是避免一次性物化全头 QKV 与全尺寸 all-to-all 缓冲：每个阶段只处理 U 个头（U < H），重复 H/U 个阶段，并在阶段间复用同一 HBM 缓冲，使峰值中间内存随 U 而非 H 缩放（p. 5，Sections 3.2–3.3；Fig. 3）。论文给出内存分析：DS-Ulysses 的中间张量与 H 成正比，而 UPipe 用 U 替换 H，形成可调的运行时-内存权衡；最小可行 U 为 U=C（U 可被 C 整除）（p. 5–6，Sections 3.3–3.4）。为兼容 GQA，UPipe 引入调度策略：尽早通信尽可能多的唯一 KV 头，并在后续阶段通过“乱序”选择查询来复用它们，从而减少冗余 KV 通信（p. 6–7，Section 4.1；Fig. 4）。实现上，实验将 UPipe 集成到 TorchTitan，使用 FlashAttention-3 kernel，并与其他省内存组件结合（tiled FFN/RMSNorm、融合 linear+cross-entropy loss、以及带 CPU offloading 的激活检查点）以支持多百万 token 训练（p. 6，Section 4；p. 7，Section 5.1）。
- 论文提出一种专用于 Mamba 风格选择性 SSM mixer 块的张量并行推理设计。首先，引入 SSM cache 以避免在 prefill 与 decode 间对提示重复处理：cache 存储（a）处理提示后每层的紧凑 SSM 循环状态与（b）因果深度卷积的短历史；在 TP 下，cache 按通道分片，使每个 GPU 仅存储其拥有通道的 cache 条目，从而在解码时 cache 读写保持 GPU 本地（p. 4，Section IV-A；p. 5，Fig. 2 caption）。其次，使用“智能按通道切分”（channel splitter），沿通道维度切分权重与激活，使每个 GPU 能在连续的本地通道分片上执行对局部布局敏感的算子（通道可分离的 depthwise Conv1D 与 SSM scan/update），这些路径无需通信（p. 5，Section IV-B）。该设计将朴素切分下每块需要的通信集合从 4 次降为每块 2 次 AllReduce：一次在 SSM 参数投影后，一次在残差流边界（p. 5，Section IV-B）。第三，显式处理打包的 SSM 参数张量：不直接切片打包的 SSM_parameters（可能切断 Δ、B、C 等逻辑字段），而是解包逻辑字段并进行 TP 感知放置——Δ 随通道分片，同时确保本地状态更新所需的其他量本地可得（token 相关的 B、C 本地产生；每通道 A、D 按需复制/存储），使融合 SSM kernel 能在连续本地分片上运行且无需额外集合通信（p. 6，Section IV-C）。最后，可选地对剩余 AllReduce 负载进行量化：将通信张量从 FP32 量化到 FP16 进行传输/归约，之后再反量化，以降低带宽需求，同时保持 SSM/卷积 kernel 不变（p. 6，Section IV-D）。该设计声称可扩展到 Mamba-2、Falcon-Mamba 与 Zamba，仅需适配实现特定的打包布局；对 Zamba 的注意力组件则在适用处使用标准 TP（p. 6，Section IV-E）。
- 论文采用 ColBERT 风格晚交互：在查询 token 序列 Q 与文档 token 序列 C 之间用 MaxSim 打分（p. 3，“Late Interaction”）。研究将文档表示以与查询无关的方式压缩到固定预算 m 个向量，提出四种方法（p. 2，Introduction；p. 3–5，Section 4–5）：（1）SeqResize：参数化方法，用双向 transformer 编码全文档，pad/截断到固定长度 n0，再用沿序列维度操作的两层 MLP 将长度 n0 投影到长度 m（p. 3–4，Section 4.1）。（2）MemTok：参数化方法，在文档 token 序列后追加 m 个可学习“记忆 token”，运行 transformer 编码器，并用记忆 token 的最终隐状态作为压缩表示（p. 4，Section 4.2）。（3）H-Pool：非参数方法，计算两两余弦距离并用 Ward linkage 做凝聚层次聚类，合并直到剩余所需簇数；每簇用成员向量均值表示，并可选择保留 m′ 个受保护 token（p. 4，Section 4.3）。（4）AGC（Attention-Guided Clustering，注意力引导聚类）：论文提出的方法。它向文档追加可训练“通用查询”token，使用其最后一层注意力计算 token 显著性分数（对头与通用查询取平均），选择 top-m 显著 token 作为质心，将所有 token 按余弦相似度分配到最近质心（硬聚类），并将每个压缩向量构造为簇内 token 的显著性加权平均（p. 5–6，Section 5.1–5.3；Fig. 2）。
- 信息不足。
- 这是一篇概念/定位论文而非实证研究。作者通过综合信息行为与 HCI 理论提出 IEP 框架，并用该框架在“交互原语”层面分析 KG 探索界面及其认识论前提。首先，他们将 IEP 与既有概念对照：Belkin 的异常知识状态（ASK）、探索式搜索、意义建构、信息觅食、上手/定向、偶然发现与认知负荷理论。他们认为这些概念都未充分捕捉首次接触条件，因为许多都预设存在起点和/或目标，而 IEP 的定义恰在于两者皆缺失（p. 2–4，Section 2；Table 1）。其次，他们将 IEP 表述为首次接触时三种相互依赖障碍的共现：范围不确定性（不知道 KG 包含什么或从何开始）、本体不透明（难以理解概念模式/本体）、查询无能（难以使用 SPARQL）（p. 5–6，Section 3.4–3.5）。第三，他们将 KG 探索界面分解为常见交互原语（如搜索、分面选择、模式浏览、图导航、可视化查询构造、自然语言问答），并识别每种原语对用户知识的假设。他们认为这些原语与 IEP 结构性错配，因为它们要求首次接触时并不存在的认识论条件（p. 7，Section 4.2；Table 2）。基于该分析，他们提出“范围揭示（scope revelation）”作为缺失的交互原语，并讨论其可能形式（p. 8，Section 4.4）。

### 隐私/安全
- 论文提出 HAT-Lab（Human-Agent Trust Laboratory，人-智能体信任实验室），一个用于沉浸式行为实验的高保真平台：让参与者在真实、目标导向任务中获得智能体辅助，同时可程序化注入 AMD 攻击（p. 2–5，Section III）。平台基于“信任边界框架”，将用户信任分解为三条边界——感知、记忆与行动——并设计违反各边界的攻击（p. 4，Section III.B）。HAT-Lab 包含九个覆盖日常与职业领域的场景；Table I 将每个场景映射到边界、攻击类型、分配任务与后果（p. 5，Table I）。平台架构包括：带真实资源的实验前端（如模拟网页邮箱、PDF 简历、代码仓库）、攻击配置层、基于 LangChain 的编排后端（为每位参与者创建隔离的智能体实例）、以及记录模块（捕获用户输入、UI 事件与 LLM trace）（p. 4–5，Section III.C；Fig. 2）。一项大规模用户研究（N=303）在 Prolific 上进行，采用混合设计：被试间分配三种护栏之一（静态免责声明、持续提醒、交互式警报），被试内通过区组设计暴露于三个场景以管理疲劳（p. 6，Section IV.A；Fig. 3–4）。主要易感性指标包括风险感知率（注意到异常/可疑）与准确识别率（正确描述底层攻击机制）（p. 7–8，Section IV.D）。论文报告使用非参数统计检验（Mann–Whitney U、Fisher 精确检验）（p. 8，Section IV.D）。平台还在攻击刺激可复现性（ASR）、跨模型泛化（COMET）与真实感/可用性（用户反馈）方面进行了验证（p. 6，Section III.D；p. 16–17，Appendix D–F；Table IX；Fig. 11）。

### 鲁棒性
- 论文提出 DEEPSYNTH：一个包含 120 个专家撰写任务的基准，用于评估基于网页的信息综合能力，并要求结构化、可验证输出。任务要求智能体浏览与搜索网页、阅读多份文档/表格并进行分析，产出简洁的 JSON/字典输出以便自动检查（p. 3，Section 2；p. 6，Section 3 Metrics）。基准通过多阶段人工流程构建：（a）数据源识别，（b）假设生成，（c）通过人工分析验证假设，（d）将任务表述为包含中间步骤、支持证据与答案（p. 4，Section 2.2；Fig. 2）。来源被筛选为官方/可信，并按有用性与可验证性过滤（p. 4，Section 2.2）。任务包含金标准与人工标注的推理链（p. 2，Introduction；p. 5，Section 2.2 Task Formulation）。第二个独立标注阶段仅保留两位标注者答案一致的任务（p. 5，Section 2.2 Data Validation）。评估使用严格的 JSON 键值精确匹配（EM）与基于键值对的 precision/recall/F1 的部分匹配，并提供一个 LLM-as-a-judge 的“软”指标以容忍小的语义/数值差异（p. 6，Section 3 Metrics；Fig. 10）。作者对多种 LLM 与带工具使用的智能体框架（网页搜索/浏览、代码解释器、文档处理）进行基准测试，并做了包括工具消融与提供真实中间步骤以测试规划作用的分析（p. 6-8，Sections 4-5；Table 3）。
- 论文将 LLM 建模为在提示 \(x\sim D\) 上对响应的随机策略 \(\pi_\theta(\cdot|x)\)，验证器奖励为二值 \(r(x,y)\in\{0,1\}\)（p. 3，Section 2）。每提示成功率为 \(p_\theta(x)=\mathbb{E}_{y\sim\pi_\theta}[r(x,y)]\)（Eq. (1)，p. 3），pass@k 为 \(J_k(\theta)=\mathbb{E}_{x\sim D}[1-(1-p_\theta(x))^k]\)（p. 3，Section 2）。通过链式法则推导 pass@k 梯度 \(\nabla J_k(\theta)=\mathbb{E}_{x\sim D}[w_k(p_\theta(x))\nabla p_\theta(x)]\)，其中权重 \(w_k(p)=k(1-p)^{k-1}\)，强调低成功率提示（Eq. (2)–(3)，p. 4）。为刻画共享参数下跨提示交互，定义提示梯度相似核 \(\kappa_\theta(x,x')=\langle \nabla p_\theta(x),\nabla p_\theta(x')\rangle\)（Eq. (5)，p. 5），并以该核符号定义正/负提示干扰（Definition 3.1，p. 5）。随后通过内积 \(\langle \nabla J_k(\theta),\nabla J_1(\theta)\rangle\) 分析梯度冲突，引入一致性分数 \(a_\theta(x)=\langle \nabla J_1(x;\theta),\nabla J_1(\theta)\rangle\)（Eq. (8)，p. 7），并证明 \(\langle \nabla J_k,\nabla J_1\rangle=\mathbb{E}[w_{k,\theta}(x)a_\theta(x)]\) 以及等价的协方差分解（Proposition 4.1，Eq. (9)–(10)，p. 7）。在策略平滑性假设下（Assumption 4.3，p. 8），给出冲突的充分条件（Corollary 4.4，p. 10），研究增大 k 如何引入超过阈值后发生冲突（Proposition 4.5，p. 10），并证明在显式步长条件下，一步 pass@k 梯度上升可同时提升 pass@k 而降低 pass@1（Proposition 4.6，p. 11）。经验上，他们在 MATH 上用最终隐层梯度与蒙特卡洛估计来估计一致性分数与 pass@k 权重（p. 11–12，Section 5）。
- SELAUR 是一个将不确定性估计注入奖励塑形的 LLM 智能体强化学习框架。它包含三个模块：（1）token 级不确定性估计，（2）聚合为步骤与轨迹级信号，（3）面向失败的奖励塑形（Fig. 1；p. 4 Section 3）。不确定性估计方面，SELAUR 从模型 token 概率分布计算三种 token 级指标：词表归一化熵、最小置信度（1 减去所选 token 概率）、以及基于 top-2 概率差并经 sigmoid（带缩放）的 margin 指标（p. 5 Section 3.1）。三者加权求和得到统一 token 级不确定性（p. 5 Section 3.1）。在每一步内对 token 不确定性取平均得到步骤不确定性，并用指数折扣加权（强调后期步骤）聚合为轨迹不确定性（p. 5 Section 3.2）。奖励塑形主要修改失败情形：当轨迹失败时，将每步奖励替换/增强为“步骤相关权重 × 归一化步骤不确定性”（其设置中 wt=0.95），并将轨迹奖励设为轨迹不确定性 U(τ)；成功轨迹则使用标准奖励（Eq. 1–2；p. 6 Section 3.3）。实验与 PPO、RLOO、GRPO、GiGPO 对比，报告成功率（以及 WebShop 任务分数），并给出训练超参与交互步数上限（p. 6 Section 4.1）。
- 论文在 n 玩家折扣马尔可夫博弈中形式化 MA-IL（乘积策略），并用占用度量（仅状态与状态-动作）连接模仿目标与诱导行为（p. 3，Section 3.1）。以纳什间隙定义可被利用性：对学习到的联合策略，取各玩家对其的最佳响应所能带来的价值提升的最大值（p. 4，Definition 4）。分析分三阶段：（1）精确度量匹配：证明若两策略具有相同状态-动作占用度量，则在被访问区域上它们一致（Theorem 1，p. 5；证明见 Appendix B.1）。在全状态支持下，精确状态-动作匹配蕴含学习策略等于专家纳什均衡，从而纳什间隙为 0（Corollary 1，p. 5）。随后构造反例表明：仅状态匹配仍可产生与有效时域线性增长的纳什间隙（Lemma 1，p. 5–6，含 Fig. 1）；即便精确状态-动作匹配，在专家未访问所有状态时也可能失败（Theorem 2，p. 6）。（2）紧下界的不可处理性：定义“紧纳什间隙下界” m_rho(G, eps_rho) 为在固定占用匹配误差下可达到的最佳纳什间隙，并证明在双矩阵博弈中计算它是 PPAD-hard（Theorem 3，p. 7），并扩展到马尔可夫博弈（Corollary 2，p. 7）。（3）可处理上界：引入均衡处最佳响应对应关系的 δ-连续性（Definition 6，p. 8），并推导以 BC 误差与 δ 表示的纳什间隙上界。在支配策略均衡下（Definition 8，p. 9），得到 NashGap(π) ≤ 2n ε_BC/(1−γ)^2（Lemma 3，p. 9；证明 Appendix C.1）。更一般地，在 δ-连续博弈中，得到 NashGap(π) ≤ (2n ε_BC + δ(ε_BC))/(1−γ)^2（Lemma 4，p. 9；证明 Appendix C.2）。
- 提出框架 Generative Pseudo-Labeling（GPL），为未曝光的用户-物品对生成内容感知的伪标签，并用真实标签与伪标签的联合目标训练预排序模型（p. 2–5，Sections 3.2–3.4）。首先，仅用内容将物品离散化为语义标识符（SID）：冻结多模态编码器生成物品嵌入，RQ-VAE 将嵌入量化为分层码索引（SID），并用重建/承诺损失训练以避免交互诱导偏差（p. 3，Section 3.3.1；p. 10，Appendix A.2）。其次，将预训练开源 LLM 用 LoRA（rank=8）适配，并用 next-token prediction 训练其根据用户 SID 历史预测下一个可能 SID；通过对最频繁前 10% 物品做基于频率的下采样来降低流行度偏差（p. 3–4，Section 3.3.2）。推理时用分层 beam search 解码 B 个候选 SID，并通过查表映射到真实物品；词表外 SID 回退到冻结多模态空间中的最近邻检索（p. 4，Section 3.3.2）。这些生成物品作为用户特定“兴趣锚点”。对每个未曝光候选，GPL 将伪标签定义为：在冻结多模态嵌入空间中，候选与任一锚点的最大余弦相似度（max-pooling）经 sigmoid 与温度参数 τ 变换（p. 4，Section 3.3.3）。第三，GPL 用不确定性感知权重校准伪标签可靠性：权重来自（i）锚点间语义离散度，（ii）与用户历史物品的一致性，（iii）LLM 内在置信度（解码路径平均 log-prob），并组合归一化（p. 4–5，Section 3.4.1）。最后，预排序模型用曝光数据的 BCE 与未曝光伪标注数据的置信加权 BCE 联合训练：L = L_al + λ L_pl，其余组件保持冻结（p. 5，Section 3.4.2）。所有 LLM 推理与伪标签生成均离线执行并缓存，目标是在线零延迟开销（p. 2，Introduction；p. 5，Section 3.5）。

---

## 3. 趋势与洞见

### 热门话题
- 幻觉/事实性（2 篇）
- 其他（14 篇）
- 隐私/安全（1 篇）
- 鲁棒性（5 篇）

### 技术趋势
- 对智能体可靠性的关注持续增长：过程审计、通信陷阱与运行时控制。
- 围绕 PEFT 与模型合并的方法学与工程仍然活跃（超参混淆、逐层启发式）。

### 跨领域关联
- 安全/隐私越来越被视为工具使用型智能体的系统问题（中介层、可审计性、治理信号）。
- 成本/延迟关注（推理效率、CoT 压缩）与评估方法与部署约束相交织。

---

## 4. Top 5 推荐论文

按整体重要性与洞见（基于可用证据）排序：

### 1. Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training（为何优化 Pass@k 会降低 Pass@1：LLM 后训练中的提示干扰）
**类别**：鲁棒性  
**重要性**：⭐⭐⭐⭐  
**作者**：Anas Barakat, Souradip Chakraborty, Khushbu Pahwa, Amrit Singh Bedi  
**链接**：http://arxiv.org/abs/2602.21189v1

**核心问题**：  
Pass@k 是可验证 LLM 任务（如数学/代码）的标准指标：模型可独立采样 k 个解，由验证器检查正确性；若任一通过则成功（p. 3，Section 2）。该指标推动了通过策略梯度直接优化 pass@k 的后训练方法，以匹配推理时的多采样流程（p. 1，Section 1；p. 4，Section 2）。然而，多项先前工作报告一个反复出现且在实践中成问题的权衡：优化 pass@k 可能提升 pass@k，却降低 pass@1（单次成功率）（p. 1，Section 1）。论文认为这很重要，因为 pass@1 常仍是运维约束：受延迟/成本预算限制、验证器覆盖不完美、以及需要可靠的单次回退方案（p. 2，“Why this degradation matters.”）。核心问题因此是解释：为何以及在何种情况下，面向多样本成功（pass@k）的推理感知优化会损害单样本性能（pass@1），尽管对每个提示而言 pass@k 梯度只是 pass@1 梯度的正比例缩放（p. 7，Section 4.1；p. 4，Section 2）。作者将开放问题表述为理解这种退化背后的机制，并给出其发生条件，从而使未来推理感知微调能在提升多次尝试性能的同时避免牺牲 pass@1（p. 2，“Open question.”；p. 15，Section 7）。

**方法新颖性**：  
论文将 LLM 建模为在提示 \(x\sim D\) 上对响应的随机策略 \(\pi_\theta(\cdot|x)\)，验证器奖励为二值 \(r(x,y)\in\{0,1\}\)（p. 3，Section 2）。每提示成功率为 \(p_\theta(x)=\mathbb{E}_{y\sim\pi_\theta}[r(x,y)]\)（Eq. (1)，p. 3），pass@k 为 \(J_k(\theta)=\mathbb{E}_{x\sim D}[1-(1-p_\theta(x))^k]\)（p. 3，Section 2）。通过链式法则推导 pass@k 梯度 \(\nabla J_k(\theta)=\mathbb{E}_{x\sim D}[w_k(p_\theta(x))\nabla p_\theta(x)]\)，其中权重 \(w_k(p)=k(1-p)^{k-1}\)，强调低成功率提示（Eq. (2)–(3)，p. 4）。为刻画共享参数下跨提示交互，定义提示梯度相似核 \(\kappa_\theta(x,x')=\langle \nabla p_\theta(x),\nabla p_\theta(x')\rangle\)（Eq. (5)，p. 5），并以该核符号定义正/负提示干扰（Definition 3.1，p. 5）。随后通过内积 \(\langle \nabla J_k(\theta),\nabla J_1(\theta)\rangle\) 分析梯度冲突，引入一致性分数 \(a_\theta(x)=\langle \nabla J_1(x;\theta),\nabla J_1(\theta)\rangle\)（Eq. (8)，p. 7），并证明 \(\langle \nabla J_k,\nabla J_1\rangle=\mathbb{E}[w_{k,\theta}(x)a_\theta(x)]\) 以及等价的协方差分解（Proposition 4.1，Eq. (9)–(10)，p. 7）。在策略平滑性假设下（Assumption 4.3，p. 8），给出冲突的充分条件（Corollary 4.4，p. 10），研究增大 k 如何引入超过阈值后发生冲突（Proposition 4.5，p. 10），并证明在显式步长条件下，一步 pass@k 梯度上升可同时提升 pass@k 而降低 pass@1（Proposition 4.6，p. 11）。经验上，他们在 MATH 上用最终隐层梯度与蒙特卡洛估计来估计一致性分数与 pass@k 权重（p. 11–12，Section 5）。

**关键贡献**：
- 通过 pass@1 梯度相似核定义“提示干扰”，并形式化正/负干扰（p. 5，Definition 3.1；Eq. (5)）。
- 将 pass@k 与 pass@1 的梯度冲突刻画为依赖 pass@k 权重与提示一致性分数的内积，并给出协方差分解（p. 7，Proposition 4.1）。
- 给出充分条件（以及 k 阈值结果）：当负干扰提示被上权重时，增大 k 会鼓励梯度冲突（p. 10，Corollary 4.4；Proposition 4.5）。
- 证明在梯度冲突与步长条件下，pass@k 梯度步可提升 pass@k 同时降低 pass@1（p. 11，Proposition 4.6）。
- 在 MATH 上用两种 LLM 经验验证机制：困难提示往往一致性为负且获得更大 pass@k 权重，导致估计内积为负（p. 11–13，Section 5；Fig. 6）。

**结果**：  
理论：证明总体梯度内积 \(\langle \nabla J_k(\theta),\nabla J_1(\theta)\rangle\) 等于 \(\mathbb{E}[w_{k,\theta}(x)a_\theta(x)]\)，并可因 pass@k 权重与一致性分数的协方差而为负（p. 7，Proposition 4.1）。给出负干扰提示占主导时内积为负的充分条件（p. 10，Corollary 4.4），并在成功率分离假设下给出超过阈值 \(k^\star\) 后发生冲突（p. 10，Proposition 4.5）。还证明在足够小步长下，一步 pass@k 梯度上升可严格降低 pass@1 且提升 pass@k（p. 11，Proposition 4.6）。

玩具例子：两提示重叠情形下，报告 pass@10 步（\(\eta=5\)）使 \(J_1\) 从 \(\approx 0.48\) 降至 \(\approx 0.46\)，同时 \(J_{10}\) 从 \(\approx 0.83\) 升至 \(0.95\)（p. 7，Section 3.3）。

实验（MATH）：使用 DeepSeek-R1-Distill-Llama-8B 与 DeepSeek-R1-Distill-Qwen-7B，计算一致性分数与 pass@k 权重，显示困难提示倾向于负一致性且获得更大 pass@k 权重（p. 12，Section 5；Fig. 6）。报告困难与容易提示的极端权重差异（声称 \(\sim 10^{28}:1\)），以及负的估计内积表明梯度冲突；所示配置下内积为 \(-0.613\)（Llama-8B）与 \(-181\)（Qwen-7B）（p. 12–13，Section 5；Fig. 6 caption）。并在 Llama-8B 的额外阈值配置上保持鲁棒，内积范围 \(-0.49\) 到 \(-0.65\)（p. 24，Appendix D.2）。

---

### 2. VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation（VAUQ：用于 LVLM 自我评估的视觉感知不确定性量化）
**类别**：幻觉/事实性  
**重要性**：⭐⭐⭐⭐  
**作者**：Seongheon Park, Changdae Oh, Hyeong Kyu Choi, Xuefeng Du, Sharon Li  
**链接**：http://arxiv.org/abs/2602.21054v1

（以下各小节内容已在上文对应部分翻译，此处保持原结构与信息不变。）

---

### 3. Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking（解绑定 Ulysses：通过按头分块实现内存高效的上下文并行）
**类别**：其他  
**重要性**：⭐⭐⭐⭐  
**作者**：Ravi Ghadia, Maksim Abraham, Sergei Vorobyov, Max Ryabinin  
**链接**：http://arxiv.org/abs/2602.21196v1

---

### 4. Tool Building as a Path to "Superintelligence"（工具构建作为通往“超级智能”的路径）
**类别**：其他  
**重要性**：⭐⭐⭐⭐  
**作者**：David Koplow, Tomer Galanti, Tomaso Poggio  
**链接**：http://arxiv.org/abs/2602.21061v1

---

### 5. Test-Time Training with KV Binding Is Secretly Linear Attention（带 KV 绑定的测试时训练本质上是线性注意力）
**类别**：其他  
**重要性**：⭐⭐⭐⭐  
**作者**：Junchen Liu, Sven Elflein, Or Litany, Zan Gojcic, Ruilong Li  
**链接**：http://arxiv.org/abs/2602.21204v1

---

## 5. 总结与展望

### 今日要点
- 本报告总结了 22 篇深度解读分析。
- 覆盖类别：幻觉/事实性、其他、隐私/安全、鲁棒性

### 关键进展
- 多篇论文从系统层面瞄准智能体可靠性与安全治理（审计、中介、遥测）。
- 推理成本与评估方法持续成为一等研究议题。

### 未来方向
- 将过程级审计信号与运行时策略结合，构建可部署的“智能体防火墙 + 审计”闭环。
- 在真实工具环境与对抗条件下验证泛化；明确报告证据缺失之处。

---

*报告生成时间：2026-02-25 23:23:52*
