{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"output.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \n",
    "    #\"journal\":{\n",
    "    #    \"file\": \"pubs.bib\",\n",
    "    #    \"venuekey\" : \"journal\",\n",
    "    #    \"venue-pretext\" : \"\",\n",
    "    #    \"collection\" : {\"name\":\"publications\",\n",
    "    #                    \"permalink\":\"/publication/\"}\n",
    "    #} \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Racing on the Negative Force: Efficient Vulnerability Root-Cause Analysis through Reinforcement Learning on Counterexamples'), \n",
      "    ('booktitle', '33th USENIX Security Symposium (USENIX Security 24)'), \n",
      "    ('year', '2024')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Xu, Dandan'), Person('Tang, Di'), Person('Chen, Yi'), Person('Wang, XiaoFeng'), Person('Chen, Kai'), Person('Tang, Haixu'), Person('Li, Longxing')])]))\n",
      "SUCESSFULLY PARSED xu2024racing: \" Racing on the Negative Force: Efficient Vulnerability Root-C ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep Neural Networks for Runtime Trojan Injection'), \n",
      "    ('booktitle', '33th USENIX Security Symposium (USENIX Security 24)'), \n",
      "    ('year', '2024')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Wang, Zihao'), Person('Tang, Di'), Person('Wang, XiaoFeng'), Person('He, Wei'), Person('Geng, Zhaoyang'), Person('Wang, Wenhao')])]))\n",
      "SUCESSFULLY PARSED wang2024tossing: \" Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', '$\\\\{$HOMESPY$\\\\}$: The Invisible Sniffer of Infrared Remote Control of Smart $\\\\{$TVs$\\\\}$'), \n",
      "    ('booktitle', '32nd USENIX Security Symposium (USENIX Security 23)'), \n",
      "    ('pages', '4553--4570'), \n",
      "    ('year', '2023')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Huang, Kong'), Person('Zhou, YuTong'), Person('Zhang, Ke'), Person('Xu, Jiacen'), Person('Chen, Jiongyi'), Person('Tang, Di'), Person('Zhang, Kehuan')])]))\n",
      "SUCESSFULLY PARSED huang2023homespy: \" $\\{$HOMESPY$\\}$: The Invisible Sniffer of Infrared Remote Co ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Gradient Shaping: Enhancing Backdoor Attack against Reverse Engineering'), \n",
      "    ('booktitle', 'Network and Distributed Systems Security (NDSS) Symposium 2024'), \n",
      "    ('year', '2023')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Zhu, Rui'), Person('Tang, Di'), Person('Tang, Siyuan'), Person('Tao, Guanhong'), Person('Ma, Shiqing'), Person('Wang, XiaoFeng'), Person('Tang, Haixu')])]))\n",
      "SUCESSFULLY PARSED zhu2023gradient: \" Gradient Shaping: Enhancing Backdoor Attack against Reverse  ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Sherlock on Specs: Building LTE Conformance Tests through Automated Reasoning'), \n",
      "    ('booktitle', '32th USENIX Security Symposium (USENIX Security 23)'), \n",
      "    ('year', '2023')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Chen, Yi'), Person('Tang, Di'), Person('Yao, Yepeng'), Person('Zha, Mingming'), Person('Wang, XiaoFeng'), Person('Liu, Xiaozhong'), Person('Tang, Haixu'), Person('Liu, Baoxu')])]))\n",
      "SUCESSFULLY PARSED chen2023sherlock: \" Sherlock on Specs: Building LTE Conformance Tests through Au ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models'), \n",
      "    ('booktitle', 'Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security'), \n",
      "    ('pages', '2025--2039'), \n",
      "    ('year', '2022')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Liu, Jiawei'), Person('Kang, Yangyang'), Person('Tang, Di'), Person('Song, Kaisong'), Person('Sun, Changlong'), Person('Wang, Xiaofeng'), Person('Lu, Wei'), Person('Liu, Xiaozhong')])]))\n",
      "SUCESSFULLY PARSED liu2022order: \" Order-Disorder: Imitation Adversarial Attacks for Black-box  ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Seeing the Forest for the Trees: Understanding Security Hazards in the $\\\\{$3GPP$\\\\}$ Ecosystem through Intelligent Analysis on Change Requests'), \n",
      "    ('booktitle', '31st USENIX Security Symposium (USENIX Security 22)'), \n",
      "    ('pages', '17--34'), \n",
      "    ('year', '2022'), \n",
      "    ('organization', 'IEEE')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Chen, Yi'), Person('Tang, Di'), Person('Yao, Yepeng'), Person('Zha, Mingming'), Person('Wang, XiaoFeng'), Person('Liu, Xiaozhong'), Person('Tang, Haixu'), Person('Zhao, Dongfang')])]))\n",
      "SUCESSFULLY PARSED chen2022seeing: \" Seeing the Forest for the Trees: Understanding Security Haza ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models'), \n",
      "    ('booktitle', '2022 IEEE Symposium on Security and Privacy (SP)'), \n",
      "    ('year', '2022'), \n",
      "    ('organization', 'IEEE')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Tang, Di'), Person('Zhu, Rui'), Person('Tang, Siyuan'), Person('Wang, XiaoFeng'), Person('Tang, Haixu')])]))\n",
      "SUCESSFULLY PARSED tang2022selective: \" Selective Amnesia: On Efficient, High-Fidelity and Blind Sup ... \"\n",
      "Entry('inproceedings',\n",
      "  fields=[\n",
      "    ('title', 'The trojan detection challenge'), \n",
      "    ('booktitle', 'NeurIPS 2022 Competition Track'), \n",
      "    ('pages', '279--291'), \n",
      "    ('year', '2022'), \n",
      "    ('organization', 'PMLR')],\n",
      "  persons=OrderedCaseInsensitiveDict([('author', [Person('Mazeika, Mantas'), Person('Hendrycks, Dan'), Person('Li, Huichen'), Person('Xu, Xiaojun'), Person('Hough, Sidney'), Person('Zou, Andy'), Person('Rajabi, Arezoo'), Person('Yao, Qi'), Person('Wang, Zihao'), Person('Tian, Jian'), Person('others')])]))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(bibdata\u001b[38;5;241m.\u001b[39mentries[bib_id])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m author \u001b[38;5;129;01min\u001b[39;00m bibdata\u001b[38;5;241m.\u001b[39mentries[bib_id]\u001b[38;5;241m.\u001b[39mpersons[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 48\u001b[0m     citation \u001b[38;5;241m=\u001b[39m citation\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mauthor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mauthor\u001b[38;5;241m.\u001b[39mlast_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#citation title\u001b[39;00m\n\u001b[1;32m     51\u001b[0m citation \u001b[38;5;241m=\u001b[39m citation \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m html_escape(b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            print(bibdata.entries[bib_id])\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                if len(author.first_names)>1:\n",
    "                    citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "                else:\n",
    "                    citation = citation+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
